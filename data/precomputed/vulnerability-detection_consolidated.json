{
  "task": "vulnerability detection",
  "filterMappings": {
    "overall": {
      "dataset": []
    },
    "dataset-PrimeVul": {
      "dataset": [
        "PrimeVul"
      ]
    },
    "dataset-PrimeVulPairs": {
      "dataset": [
        "PrimeVulPairs"
      ]
    },
    "dataset-PrimeVul-PrimeVulPairs": {
      "dataset": [
        "PrimeVul",
        "PrimeVulPairs"
      ]
    }
  },
  "data": {
    "Claude-4-Sonnet": {
      "overall": {
        "rank": 1,
        "Accuracy": "69.5",
        "Precision": "66.8",
        "Recall": "82.1",
        "F1 Score": "73.7",
        "P-C": "73.3",
        "P-V": "18.0",
        "P-B": "2.8",
        "P-R": "5.8"
      },
      "dataset-PrimeVul": {
        "rank": 1,
        "Accuracy": "69.5",
        "Precision": "66.8",
        "Recall": "82.1",
        "F1 Score": "73.7",
        "P-C": "-",
        "P-V": "-",
        "P-B": "-",
        "P-R": "-"
      },
      "dataset-PrimeVulPairs": {
        "rank": 22,
        "Accuracy": "-",
        "Precision": "-",
        "Recall": "-",
        "F1 Score": "-",
        "P-C": "73.3",
        "P-V": "18.0",
        "P-B": "2.8",
        "P-R": "5.8"
      },
      "dataset-PrimeVul-PrimeVulPairs": {
        "rank": 1,
        "Accuracy": "69.5",
        "Precision": "66.8",
        "Recall": "82.1",
        "F1 Score": "73.7",
        "P-C": "73.3",
        "P-V": "18.0",
        "P-B": "2.8",
        "P-R": "5.8"
      }
    },
    "GPT-4-turbo-2024-04-09": {
      "overall": {
        "rank": 2,
        "Accuracy": "59.8",
        "Precision": "57.3",
        "Recall": "89.7",
        "F1 Score": "69.9",
        "P-C": "49.5",
        "P-V": "10.7",
        "P-B": "33.0",
        "P-R": "6.8"
      },
      "dataset-PrimeVul": {
        "rank": 2,
        "Accuracy": "59.8",
        "Precision": "57.3",
        "Recall": "89.7",
        "F1 Score": "69.9",
        "P-C": "-",
        "P-V": "-",
        "P-B": "-",
        "P-R": "-"
      },
      "dataset-PrimeVulPairs": {
        "rank": 16,
        "Accuracy": "-",
        "Precision": "-",
        "Recall": "-",
        "F1 Score": "-",
        "P-C": "49.5",
        "P-V": "10.7",
        "P-B": "33.0",
        "P-R": "6.8"
      },
      "dataset-PrimeVul-PrimeVulPairs": {
        "rank": 2,
        "Accuracy": "59.8",
        "Precision": "57.3",
        "Recall": "89.7",
        "F1 Score": "69.9",
        "P-C": "49.5",
        "P-V": "10.7",
        "P-B": "33.0",
        "P-R": "6.8"
      }
    },
    "GPT-5": {
      "overall": {
        "rank": 3,
        "Accuracy": "67.3",
        "Precision": "67.9",
        "Recall": "70.5",
        "F1 Score": "69.2",
        "P-C": "80.3",
        "P-V": "13.5",
        "P-B": "2.5",
        "P-R": "3.7"
      },
      "dataset-PrimeVul": {
        "rank": 3,
        "Accuracy": "67.3",
        "Precision": "67.9",
        "Recall": "70.5",
        "F1 Score": "69.2",
        "P-C": "-",
        "P-V": "-",
        "P-B": "-",
        "P-R": "-"
      },
      "dataset-PrimeVulPairs": {
        "rank": 20,
        "Accuracy": "-",
        "Precision": "-",
        "Recall": "-",
        "F1 Score": "-",
        "P-C": "80.3",
        "P-V": "13.5",
        "P-B": "2.5",
        "P-R": "3.7"
      },
      "dataset-PrimeVul-PrimeVulPairs": {
        "rank": 3,
        "Accuracy": "67.3",
        "Precision": "67.9",
        "Recall": "70.5",
        "F1 Score": "69.2",
        "P-C": "80.3",
        "P-V": "13.5",
        "P-B": "2.5",
        "P-R": "3.7"
      }
    },
    "GPT-4o-2024-11-20": {
      "overall": {
        "rank": 4,
        "Accuracy": "60.3",
        "Precision": "58.3",
        "Recall": "83.3",
        "F1 Score": "68.6",
        "P-C": "41.5",
        "P-V": "28.2",
        "P-B": "14.2",
        "P-R": "16.2"
      },
      "dataset-PrimeVul": {
        "rank": 4,
        "Accuracy": "60.3",
        "Precision": "58.3",
        "Recall": "83.3",
        "F1 Score": "68.6",
        "P-C": "-",
        "P-V": "-",
        "P-B": "-",
        "P-R": "-"
      },
      "dataset-PrimeVulPairs": {
        "rank": 2,
        "Accuracy": "-",
        "Precision": "-",
        "Recall": "-",
        "F1 Score": "-",
        "P-C": "41.5",
        "P-V": "28.2",
        "P-B": "14.2",
        "P-R": "16.2"
      },
      "dataset-PrimeVul-PrimeVulPairs": {
        "rank": 4,
        "Accuracy": "60.3",
        "Precision": "58.3",
        "Recall": "83.3",
        "F1 Score": "68.6",
        "P-C": "41.5",
        "P-V": "28.2",
        "P-B": "14.2",
        "P-R": "16.2"
      }
    },
    "Llama-3.1-70B-Instruct": {
      "overall": {
        "rank": 5,
        "Accuracy": "57.2",
        "Precision": "55.5",
        "Recall": "89.1",
        "F1 Score": "68.4",
        "P-C": "18.3",
        "P-V": "0.3",
        "P-B": "59.7",
        "P-R": "21.7"
      },
      "dataset-PrimeVul": {
        "rank": 5,
        "Accuracy": "57.2",
        "Precision": "55.5",
        "Recall": "89.1",
        "F1 Score": "68.4",
        "P-C": "-",
        "P-V": "-",
        "P-B": "-",
        "P-R": "-"
      },
      "dataset-PrimeVulPairs": {
        "rank": 8,
        "Accuracy": "-",
        "Precision": "-",
        "Recall": "-",
        "F1 Score": "-",
        "P-C": "18.3",
        "P-V": "0.3",
        "P-B": "59.7",
        "P-R": "21.7"
      },
      "dataset-PrimeVul-PrimeVulPairs": {
        "rank": 5,
        "Accuracy": "57.2",
        "Precision": "55.5",
        "Recall": "89.1",
        "F1 Score": "68.4",
        "P-C": "18.3",
        "P-V": "0.3",
        "P-B": "59.7",
        "P-R": "21.7"
      }
    },
    "Claude-3.5-Haiku-20241022": {
      "overall": {
        "rank": 6,
        "Accuracy": "61.2",
        "Precision": "59.3",
        "Recall": "80.8",
        "F1 Score": "68.4",
        "P-C": "32.8",
        "P-V": "3.8",
        "P-B": "35.0",
        "P-R": "28.3"
      },
      "dataset-PrimeVul": {
        "rank": 6,
        "Accuracy": "61.2",
        "Precision": "59.3",
        "Recall": "80.8",
        "F1 Score": "68.4",
        "P-C": "-",
        "P-V": "-",
        "P-B": "-",
        "P-R": "-"
      },
      "dataset-PrimeVulPairs": {
        "rank": 18,
        "Accuracy": "-",
        "Precision": "-",
        "Recall": "-",
        "F1 Score": "-",
        "P-C": "32.8",
        "P-V": "3.8",
        "P-B": "35.0",
        "P-R": "28.3"
      },
      "dataset-PrimeVul-PrimeVulPairs": {
        "rank": 6,
        "Accuracy": "61.2",
        "Precision": "59.3",
        "Recall": "80.8",
        "F1 Score": "68.4",
        "P-C": "32.8",
        "P-V": "3.8",
        "P-B": "35.0",
        "P-R": "28.3"
      }
    },
    "Gemini-2.5-Pro-05-06": {
      "overall": {
        "rank": 7,
        "Accuracy": "54.5",
        "Precision": "53.7",
        "Recall": "92.9",
        "F1 Score": "68.1",
        "P-C": "25.6",
        "P-V": "72.4",
        "P-B": "0.5",
        "P-R": "1.5"
      },
      "dataset-PrimeVul": {
        "rank": 7,
        "Accuracy": "54.5",
        "Precision": "53.7",
        "Recall": "92.9",
        "F1 Score": "68.1",
        "P-C": "-",
        "P-V": "-",
        "P-B": "-",
        "P-R": "-"
      },
      "dataset-PrimeVulPairs": {
        "rank": 23,
        "Accuracy": "-",
        "Precision": "-",
        "Recall": "-",
        "F1 Score": "-",
        "P-C": "25.6",
        "P-V": "72.4",
        "P-B": "0.5",
        "P-R": "1.5"
      },
      "dataset-PrimeVul-PrimeVulPairs": {
        "rank": 7,
        "Accuracy": "54.5",
        "Precision": "53.7",
        "Recall": "92.9",
        "F1 Score": "68.1",
        "P-C": "25.6",
        "P-V": "72.4",
        "P-B": "0.5",
        "P-R": "1.5"
      }
    },
    "Gemma-3-27b-it": {
      "overall": {
        "rank": 8,
        "Accuracy": "62.0",
        "Precision": "60.6",
        "Recall": "76.9",
        "F1 Score": "67.8",
        "P-C": "35.8",
        "P-V": "8.2",
        "P-B": "30.2",
        "P-R": "25.8"
      },
      "dataset-PrimeVul": {
        "rank": 8,
        "Accuracy": "62.0",
        "Precision": "60.6",
        "Recall": "76.9",
        "F1 Score": "67.8",
        "P-C": "-",
        "P-V": "-",
        "P-B": "-",
        "P-R": "-"
      },
      "dataset-PrimeVulPairs": {
        "rank": 7,
        "Accuracy": "-",
        "Precision": "-",
        "Recall": "-",
        "F1 Score": "-",
        "P-C": "35.8",
        "P-V": "8.2",
        "P-B": "30.2",
        "P-R": "25.8"
      },
      "dataset-PrimeVul-PrimeVulPairs": {
        "rank": 8,
        "Accuracy": "62.0",
        "Precision": "60.6",
        "Recall": "76.9",
        "F1 Score": "67.8",
        "P-C": "35.8",
        "P-V": "8.2",
        "P-B": "30.2",
        "P-R": "25.8"
      }
    },
    "Llama-3.3-70B-Instruct": {
      "overall": {
        "rank": 9,
        "Accuracy": "62.3",
        "Precision": "61.6",
        "Recall": "73.4",
        "F1 Score": "67.0",
        "P-C": "12.8",
        "P-V": "0.5",
        "P-B": "79.3",
        "P-R": "7.4"
      },
      "dataset-PrimeVul": {
        "rank": 9,
        "Accuracy": "62.3",
        "Precision": "61.6",
        "Recall": "73.4",
        "F1 Score": "67.0",
        "P-C": "-",
        "P-V": "-",
        "P-B": "-",
        "P-R": "-"
      },
      "dataset-PrimeVulPairs": {
        "rank": 17,
        "Accuracy": "-",
        "Precision": "-",
        "Recall": "-",
        "F1 Score": "-",
        "P-C": "12.8",
        "P-V": "0.5",
        "P-B": "79.3",
        "P-R": "7.4"
      },
      "dataset-PrimeVul-PrimeVulPairs": {
        "rank": 9,
        "Accuracy": "62.3",
        "Precision": "61.6",
        "Recall": "73.4",
        "F1 Score": "67.0",
        "P-C": "12.8",
        "P-V": "0.5",
        "P-B": "79.3",
        "P-R": "7.4"
      }
    },
    "GPT-4.1-2025-04-14": {
      "overall": {
        "rank": 10,
        "Accuracy": "59.8",
        "Precision": "61.2",
        "Recall": "62.2",
        "F1 Score": "61.7",
        "P-C": "90.8",
        "P-V": "2.2",
        "P-B": "0.0",
        "P-R": "7.0"
      },
      "dataset-PrimeVul": {
        "rank": 10,
        "Accuracy": "59.8",
        "Precision": "61.2",
        "Recall": "62.2",
        "F1 Score": "61.7",
        "P-C": "-",
        "P-V": "-",
        "P-B": "-",
        "P-R": "-"
      },
      "dataset-PrimeVulPairs": {
        "rank": 10,
        "Accuracy": "-",
        "Precision": "-",
        "Recall": "-",
        "F1 Score": "-",
        "P-C": "90.8",
        "P-V": "2.2",
        "P-B": "0.0",
        "P-R": "7.0"
      },
      "dataset-PrimeVul-PrimeVulPairs": {
        "rank": 10,
        "Accuracy": "59.8",
        "Precision": "61.2",
        "Recall": "62.2",
        "F1 Score": "61.7",
        "P-C": "90.8",
        "P-V": "2.2",
        "P-B": "0.0",
        "P-R": "7.0"
      }
    },
    "DeepSeek-R1": {
      "overall": {
        "rank": 11,
        "Accuracy": "56.5",
        "Precision": "56.9",
        "Recall": "67.0",
        "F1 Score": "61.6",
        "P-C": "81.7",
        "P-V": "12.0",
        "P-B": "2.2",
        "P-R": "4.2"
      },
      "dataset-PrimeVul": {
        "rank": 11,
        "Accuracy": "56.5",
        "Precision": "56.9",
        "Recall": "67.0",
        "F1 Score": "61.6",
        "P-C": "-",
        "P-V": "-",
        "P-B": "-",
        "P-R": "-"
      },
      "dataset-PrimeVulPairs": {
        "rank": 14,
        "Accuracy": "-",
        "Precision": "-",
        "Recall": "-",
        "F1 Score": "-",
        "P-C": "81.7",
        "P-V": "12.0",
        "P-B": "2.2",
        "P-R": "4.2"
      },
      "dataset-PrimeVul-PrimeVulPairs": {
        "rank": 11,
        "Accuracy": "56.5",
        "Precision": "56.9",
        "Recall": "67.0",
        "F1 Score": "61.6",
        "P-C": "81.7",
        "P-V": "12.0",
        "P-B": "2.2",
        "P-R": "4.2"
      }
    },
    "Qwen3-235B-A22B": {
      "overall": {
        "rank": 12,
        "Accuracy": "55.5",
        "Precision": "56.9",
        "Recall": "59.6",
        "F1 Score": "58.2",
        "P-C": "85.2",
        "P-V": "6.8",
        "P-B": "2.9",
        "P-R": "5.1"
      },
      "dataset-PrimeVul": {
        "rank": 12,
        "Accuracy": "55.5",
        "Precision": "56.9",
        "Recall": "59.6",
        "F1 Score": "58.2",
        "P-C": "-",
        "P-V": "-",
        "P-B": "-",
        "P-R": "-"
      },
      "dataset-PrimeVulPairs": {
        "rank": 13,
        "Accuracy": "-",
        "Precision": "-",
        "Recall": "-",
        "F1 Score": "-",
        "P-C": "85.2",
        "P-V": "6.8",
        "P-B": "2.9",
        "P-R": "5.1"
      },
      "dataset-PrimeVul-PrimeVulPairs": {
        "rank": 12,
        "Accuracy": "55.5",
        "Precision": "56.9",
        "Recall": "59.6",
        "F1 Score": "58.2",
        "P-C": "85.2",
        "P-V": "6.8",
        "P-B": "2.9",
        "P-R": "5.1"
      }
    },
    "Claude-3.5-Sonnet-20241022": {
      "overall": {
        "rank": 13,
        "Accuracy": "47.7",
        "Precision": "49.9",
        "Recall": "68.9",
        "F1 Score": "57.9",
        "P-C": "77.7",
        "P-V": "9.2",
        "P-B": "5.2",
        "P-R": "8.0"
      },
      "dataset-PrimeVul": {
        "rank": 13,
        "Accuracy": "47.7",
        "Precision": "49.9",
        "Recall": "68.9",
        "F1 Score": "57.9",
        "P-C": "-",
        "P-V": "-",
        "P-B": "-",
        "P-R": "-"
      },
      "dataset-PrimeVulPairs": {
        "rank": 4,
        "Accuracy": "-",
        "Precision": "-",
        "Recall": "-",
        "F1 Score": "-",
        "P-C": "77.7",
        "P-V": "9.2",
        "P-B": "5.2",
        "P-R": "8.0"
      },
      "dataset-PrimeVul-PrimeVulPairs": {
        "rank": 13,
        "Accuracy": "47.7",
        "Precision": "49.9",
        "Recall": "68.9",
        "F1 Score": "57.9",
        "P-C": "77.7",
        "P-V": "9.2",
        "P-B": "5.2",
        "P-R": "8.0"
      }
    },
    "Grok-3-Mini (High)": {
      "overall": {
        "rank": 14,
        "Accuracy": "51.2",
        "Precision": "52.6",
        "Recall": "62.5",
        "F1 Score": "57.1",
        "P-C": "78.3",
        "P-V": "12.3",
        "P-B": "3.0",
        "P-R": "6.3"
      },
      "dataset-PrimeVul": {
        "rank": 14,
        "Accuracy": "51.2",
        "Precision": "52.6",
        "Recall": "62.5",
        "F1 Score": "57.1",
        "P-C": "-",
        "P-V": "-",
        "P-B": "-",
        "P-R": "-"
      },
      "dataset-PrimeVulPairs": {
        "rank": 1,
        "Accuracy": "-",
        "Precision": "-",
        "Recall": "-",
        "F1 Score": "-",
        "P-C": "78.3",
        "P-V": "12.3",
        "P-B": "3.0",
        "P-R": "6.3"
      },
      "dataset-PrimeVul-PrimeVulPairs": {
        "rank": 14,
        "Accuracy": "51.2",
        "Precision": "52.6",
        "Recall": "62.5",
        "F1 Score": "57.1",
        "P-C": "78.3",
        "P-V": "12.3",
        "P-B": "3.0",
        "P-R": "6.3"
      }
    },
    "Claude-3.7-Sonnet": {
      "overall": {
        "rank": 15,
        "Accuracy": "61.8",
        "Precision": "69.1",
        "Recall": "48.1",
        "F1 Score": "56.7",
        "P-C": "80.6",
        "P-V": "5.7",
        "P-B": "7.7",
        "P-R": "6.0"
      },
      "dataset-PrimeVul": {
        "rank": 15,
        "Accuracy": "61.8",
        "Precision": "69.1",
        "Recall": "48.1",
        "F1 Score": "56.7",
        "P-C": "-",
        "P-V": "-",
        "P-B": "-",
        "P-R": "-"
      },
      "dataset-PrimeVulPairs": {
        "rank": 11,
        "Accuracy": "-",
        "Precision": "-",
        "Recall": "-",
        "F1 Score": "-",
        "P-C": "80.6",
        "P-V": "5.7",
        "P-B": "7.7",
        "P-R": "6.0"
      },
      "dataset-PrimeVul-PrimeVulPairs": {
        "rank": 15,
        "Accuracy": "61.8",
        "Precision": "69.1",
        "Recall": "48.1",
        "F1 Score": "56.7",
        "P-C": "80.6",
        "P-V": "5.7",
        "P-B": "7.7",
        "P-R": "6.0"
      }
    },
    "DeepSeek-R1 (0528)": {
      "overall": {
        "rank": 16,
        "Accuracy": "56.0",
        "Precision": "58.1",
        "Recall": "55.1",
        "F1 Score": "56.6",
        "P-C": "72.5",
        "P-V": "19.7",
        "P-B": "2.2",
        "P-R": "5.7"
      },
      "dataset-PrimeVul": {
        "rank": 16,
        "Accuracy": "56.0",
        "Precision": "58.1",
        "Recall": "55.1",
        "F1 Score": "56.6",
        "P-C": "-",
        "P-V": "-",
        "P-B": "-",
        "P-R": "-"
      },
      "dataset-PrimeVulPairs": {
        "rank": 3,
        "Accuracy": "-",
        "Precision": "-",
        "Recall": "-",
        "F1 Score": "-",
        "P-C": "72.5",
        "P-V": "19.7",
        "P-B": "2.2",
        "P-R": "5.7"
      },
      "dataset-PrimeVul-PrimeVulPairs": {
        "rank": 16,
        "Accuracy": "56.0",
        "Precision": "58.1",
        "Recall": "55.1",
        "F1 Score": "56.6",
        "P-C": "72.5",
        "P-V": "19.7",
        "P-B": "2.2",
        "P-R": "5.7"
      }
    },
    "Qwen3-32B": {
      "overall": {
        "rank": 17,
        "Accuracy": "53.5",
        "Precision": "56.5",
        "Recall": "46.2",
        "F1 Score": "50.8",
        "P-C": "69.0",
        "P-V": "10.2",
        "P-B": "14.6",
        "P-R": "6.1"
      },
      "dataset-PrimeVul": {
        "rank": 17,
        "Accuracy": "53.5",
        "Precision": "56.5",
        "Recall": "46.2",
        "F1 Score": "50.8",
        "P-C": "-",
        "P-V": "-",
        "P-B": "-",
        "P-R": "-"
      },
      "dataset-PrimeVulPairs": {
        "rank": 15,
        "Accuracy": "-",
        "Precision": "-",
        "Recall": "-",
        "F1 Score": "-",
        "P-C": "69.0",
        "P-V": "10.2",
        "P-B": "14.6",
        "P-R": "6.1"
      },
      "dataset-PrimeVul-PrimeVulPairs": {
        "rank": 17,
        "Accuracy": "53.5",
        "Precision": "56.5",
        "Recall": "46.2",
        "F1 Score": "50.8",
        "P-C": "69.0",
        "P-V": "10.2",
        "P-B": "14.6",
        "P-R": "6.1"
      }
    },
    "o4-mini (Med)": {
      "overall": {
        "rank": 18,
        "Accuracy": "56.3",
        "Precision": "64.6",
        "Recall": "36.2",
        "F1 Score": "46.4",
        "P-C": "75.3",
        "P-V": "3.7",
        "P-B": "8.3",
        "P-R": "12.7"
      },
      "dataset-PrimeVul": {
        "rank": 18,
        "Accuracy": "56.3",
        "Precision": "64.6",
        "Recall": "36.2",
        "F1 Score": "46.4",
        "P-C": "-",
        "P-V": "-",
        "P-B": "-",
        "P-R": "-"
      },
      "dataset-PrimeVulPairs": {
        "rank": 6,
        "Accuracy": "-",
        "Precision": "-",
        "Recall": "-",
        "F1 Score": "-",
        "P-C": "75.3",
        "P-V": "3.7",
        "P-B": "8.3",
        "P-R": "12.7"
      },
      "dataset-PrimeVul-PrimeVulPairs": {
        "rank": 18,
        "Accuracy": "56.3",
        "Precision": "64.6",
        "Recall": "36.2",
        "F1 Score": "46.4",
        "P-C": "75.3",
        "P-V": "3.7",
        "P-B": "8.3",
        "P-R": "12.7"
      }
    },
    "Llama-3.1-8B-Instruct": {
      "overall": {
        "rank": 19,
        "Accuracy": "54.5",
        "Precision": "61.5",
        "Recall": "33.3",
        "F1 Score": "43.2",
        "P-C": "9.3",
        "P-V": "6.5",
        "P-B": "50.7",
        "P-R": "33.5"
      },
      "dataset-PrimeVul": {
        "rank": 19,
        "Accuracy": "54.5",
        "Precision": "61.5",
        "Recall": "33.3",
        "F1 Score": "43.2",
        "P-C": "-",
        "P-V": "-",
        "P-B": "-",
        "P-R": "-"
      },
      "dataset-PrimeVulPairs": {
        "rank": 24,
        "Accuracy": "-",
        "Precision": "-",
        "Recall": "-",
        "F1 Score": "-",
        "P-C": "9.3",
        "P-V": "6.5",
        "P-B": "50.7",
        "P-R": "33.5"
      },
      "dataset-PrimeVul-PrimeVulPairs": {
        "rank": 19,
        "Accuracy": "54.5",
        "Precision": "61.5",
        "Recall": "33.3",
        "F1 Score": "43.2",
        "P-C": "9.3",
        "P-V": "6.5",
        "P-B": "50.7",
        "P-R": "33.5"
      }
    },
    "Qwen3-30B-A3B": {
      "overall": {
        "rank": 20,
        "Accuracy": "54.0",
        "Precision": "61.5",
        "Recall": "30.8",
        "F1 Score": "41.0",
        "P-C": "60.9",
        "P-V": "9.9",
        "P-B": "20.4",
        "P-R": "8.8"
      },
      "dataset-PrimeVul": {
        "rank": 20,
        "Accuracy": "54.0",
        "Precision": "61.5",
        "Recall": "30.8",
        "F1 Score": "41.0",
        "P-C": "-",
        "P-V": "-",
        "P-B": "-",
        "P-R": "-"
      },
      "dataset-PrimeVulPairs": {
        "rank": 19,
        "Accuracy": "-",
        "Precision": "-",
        "Recall": "-",
        "F1 Score": "-",
        "P-C": "60.9",
        "P-V": "9.9",
        "P-B": "20.4",
        "P-R": "8.8"
      },
      "dataset-PrimeVul-PrimeVulPairs": {
        "rank": 20,
        "Accuracy": "54.0",
        "Precision": "61.5",
        "Recall": "30.8",
        "F1 Score": "41.0",
        "P-C": "60.9",
        "P-V": "9.9",
        "P-B": "20.4",
        "P-R": "8.8"
      }
    },
    "DeepSeek-V3": {
      "overall": {
        "rank": 21,
        "Accuracy": "51.5",
        "Precision": "63.6",
        "Recall": "15.7",
        "F1 Score": "25.2",
        "P-C": "39.8",
        "P-V": "0.2",
        "P-B": "52.0",
        "P-R": "8.0"
      },
      "dataset-PrimeVul": {
        "rank": 21,
        "Accuracy": "51.5",
        "Precision": "63.6",
        "Recall": "15.7",
        "F1 Score": "25.2",
        "P-C": "-",
        "P-V": "-",
        "P-B": "-",
        "P-R": "-"
      },
      "dataset-PrimeVulPairs": {
        "rank": 26,
        "Accuracy": "-",
        "Precision": "-",
        "Recall": "-",
        "F1 Score": "-",
        "P-C": "39.8",
        "P-V": "0.2",
        "P-B": "52.0",
        "P-R": "8.0"
      },
      "dataset-PrimeVul-PrimeVulPairs": {
        "rank": 21,
        "Accuracy": "51.5",
        "Precision": "63.6",
        "Recall": "15.7",
        "F1 Score": "25.2",
        "P-C": "39.8",
        "P-V": "0.2",
        "P-B": "52.0",
        "P-R": "8.0"
      }
    },
    "Qwen2.5-72B-Instruct": {
      "overall": {
        "rank": 22,
        "Accuracy": "52.3",
        "Precision": "73.2",
        "Recall": "13.1",
        "F1 Score": "22.3",
        "P-C": "14.5",
        "P-V": "1.5",
        "P-B": "81.3",
        "P-R": "2.7"
      },
      "dataset-PrimeVul": {
        "rank": 22,
        "Accuracy": "52.3",
        "Precision": "73.2",
        "Recall": "13.1",
        "F1 Score": "22.3",
        "P-C": "-",
        "P-V": "-",
        "P-B": "-",
        "P-R": "-"
      },
      "dataset-PrimeVulPairs": {
        "rank": 5,
        "Accuracy": "-",
        "Precision": "-",
        "Recall": "-",
        "F1 Score": "-",
        "P-C": "14.5",
        "P-V": "1.5",
        "P-B": "81.3",
        "P-R": "2.7"
      },
      "dataset-PrimeVul-PrimeVulPairs": {
        "rank": 22,
        "Accuracy": "52.3",
        "Precision": "73.2",
        "Recall": "13.1",
        "F1 Score": "22.3",
        "P-C": "14.5",
        "P-V": "1.5",
        "P-B": "81.3",
        "P-R": "2.7"
      }
    },
    "o3-mini (Med)": {
      "overall": {
        "rank": 23,
        "Accuracy": "50.5",
        "Precision": "61.5",
        "Recall": "12.8",
        "F1 Score": "21.2",
        "P-C": "54.7",
        "P-V": "3.5",
        "P-B": "35.8",
        "P-R": "6.0"
      },
      "dataset-PrimeVul": {
        "rank": 23,
        "Accuracy": "50.5",
        "Precision": "61.5",
        "Recall": "12.8",
        "F1 Score": "21.2",
        "P-C": "-",
        "P-V": "-",
        "P-B": "-",
        "P-R": "-"
      },
      "dataset-PrimeVulPairs": {
        "rank": 21,
        "Accuracy": "-",
        "Precision": "-",
        "Recall": "-",
        "F1 Score": "-",
        "P-C": "54.7",
        "P-V": "3.5",
        "P-B": "35.8",
        "P-R": "6.0"
      },
      "dataset-PrimeVul-PrimeVulPairs": {
        "rank": 23,
        "Accuracy": "50.5",
        "Precision": "61.5",
        "Recall": "12.8",
        "F1 Score": "21.2",
        "P-C": "54.7",
        "P-V": "3.5",
        "P-B": "35.8",
        "P-R": "6.0"
      }
    },
    "Qwen2.5-Coder-32B-Instruct": {
      "overall": {
        "rank": 24,
        "Accuracy": "51.7",
        "Precision": "70.4",
        "Recall": "12.2",
        "F1 Score": "20.8",
        "P-C": "24.0",
        "P-V": "8.0",
        "P-B": "49.0",
        "P-R": "19.0"
      },
      "dataset-PrimeVul": {
        "rank": 24,
        "Accuracy": "51.7",
        "Precision": "70.4",
        "Recall": "12.2",
        "F1 Score": "20.8",
        "P-C": "-",
        "P-V": "-",
        "P-B": "-",
        "P-R": "-"
      },
      "dataset-PrimeVulPairs": {
        "rank": 25,
        "Accuracy": "-",
        "Precision": "-",
        "Recall": "-",
        "F1 Score": "-",
        "P-C": "24.0",
        "P-V": "8.0",
        "P-B": "49.0",
        "P-R": "19.0"
      },
      "dataset-PrimeVul-PrimeVulPairs": {
        "rank": 24,
        "Accuracy": "51.7",
        "Precision": "70.4",
        "Recall": "12.2",
        "F1 Score": "20.8",
        "P-C": "24.0",
        "P-V": "8.0",
        "P-B": "49.0",
        "P-R": "19.0"
      }
    },
    "Llama-4-Scout-17B-16E-Instruct": {
      "overall": {
        "rank": 25,
        "Accuracy": "49.0",
        "Precision": "55.1",
        "Recall": "12.2",
        "F1 Score": "19.9",
        "P-C": "19.8",
        "P-V": "2.2",
        "P-B": "58.5",
        "P-R": "19.5"
      },
      "dataset-PrimeVul": {
        "rank": 25,
        "Accuracy": "49.0",
        "Precision": "55.1",
        "Recall": "12.2",
        "F1 Score": "19.9",
        "P-C": "-",
        "P-V": "-",
        "P-B": "-",
        "P-R": "-"
      },
      "dataset-PrimeVulPairs": {
        "rank": 12,
        "Accuracy": "-",
        "Precision": "-",
        "Recall": "-",
        "F1 Score": "-",
        "P-C": "19.8",
        "P-V": "2.2",
        "P-B": "58.5",
        "P-R": "19.5"
      },
      "dataset-PrimeVul-PrimeVulPairs": {
        "rank": 25,
        "Accuracy": "49.0",
        "Precision": "55.1",
        "Recall": "12.2",
        "F1 Score": "19.9",
        "P-C": "19.8",
        "P-V": "2.2",
        "P-B": "58.5",
        "P-R": "19.5"
      }
    },
    "GPT-3.5-turbo-0125": {
      "overall": {
        "rank": 26,
        "Accuracy": "45.8",
        "Precision": "40.8",
        "Recall": "9.3",
        "F1 Score": "15.1",
        "P-C": "13.0",
        "P-V": "1.8",
        "P-B": "37.4",
        "P-R": "47.9"
      },
      "dataset-PrimeVul": {
        "rank": 26,
        "Accuracy": "45.8",
        "Precision": "40.8",
        "Recall": "9.3",
        "F1 Score": "15.1",
        "P-C": "-",
        "P-V": "-",
        "P-B": "-",
        "P-R": "-"
      },
      "dataset-PrimeVulPairs": {
        "rank": 9,
        "Accuracy": "-",
        "Precision": "-",
        "Recall": "-",
        "F1 Score": "-",
        "P-C": "13.0",
        "P-V": "1.8",
        "P-B": "37.4",
        "P-R": "47.9"
      },
      "dataset-PrimeVul-PrimeVulPairs": {
        "rank": 26,
        "Accuracy": "45.8",
        "Precision": "40.8",
        "Recall": "9.3",
        "F1 Score": "15.1",
        "P-C": "13.0",
        "P-V": "1.8",
        "P-B": "37.4",
        "P-R": "47.9"
      }
    }
  }
}
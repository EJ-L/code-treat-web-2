{
  "task": "unit test generation",
  "filterMappings": {
    "overall": {}
  },
  "data": {
    "Claude-3.5-Sonnet-20241022": {
      "overall": {
        "rank": 1,
        "csr": "99.8",
        "line_coverage": "73.22",
        "branch_coverage": "43.24",
        "dataset": "symprompt",
        "lang": "python",
        "task": "unit_test_generation"
      }
    },
    "o4-mini (Med)": {
      "overall": {
        "rank": 2,
        "csr": "99.8",
        "line_coverage": "81.07",
        "branch_coverage": "47.51",
        "dataset": "symprompt",
        "lang": "python",
        "task": "unit_test_generation"
      }
    },
    "Claude-3.5-Haiku-20241022": {
      "overall": {
        "rank": 3,
        "csr": "99.7",
        "line_coverage": "44.59",
        "branch_coverage": "23.49",
        "dataset": "symprompt",
        "lang": "python",
        "task": "unit_test_generation"
      }
    },
    "Qwen3-235B-A22B": {
      "overall": {
        "rank": 4,
        "csr": "99.7",
        "line_coverage": "66.72",
        "branch_coverage": "36.23",
        "dataset": "symprompt",
        "lang": "python",
        "task": "unit_test_generation"
      }
    },
    "Claude-3.7-Sonnet": {
      "overall": {
        "rank": 5,
        "csr": "99.3",
        "line_coverage": "75.29",
        "branch_coverage": "43.65",
        "dataset": "symprompt",
        "lang": "python",
        "task": "unit_test_generation"
      }
    },
    "GPT-4-turbo-2024-04-09": {
      "overall": {
        "rank": 6,
        "csr": "99.3",
        "line_coverage": "67.70",
        "branch_coverage": "37.11",
        "dataset": "symprompt",
        "lang": "python",
        "task": "unit_test_generation"
      }
    },
    "o3-mini (Med)": {
      "overall": {
        "rank": 7,
        "csr": "99.3",
        "line_coverage": "69.70",
        "branch_coverage": "41.05",
        "dataset": "symprompt",
        "lang": "python",
        "task": "unit_test_generation"
      }
    },
    "Qwen2.5-Coder-32B-Instruct": {
      "overall": {
        "rank": 8,
        "csr": "99.3",
        "line_coverage": "64.98",
        "branch_coverage": "35.75",
        "dataset": "symprompt",
        "lang": "python",
        "task": "unit_test_generation"
      }
    },
    "Qwen3-30B-A3B": {
      "overall": {
        "rank": 9,
        "csr": "99.3",
        "line_coverage": "64.89",
        "branch_coverage": "36.52",
        "dataset": "symprompt",
        "lang": "python",
        "task": "unit_test_generation"
      }
    },
    "Claude-4-Sonnet": {
      "overall": {
        "rank": 10,
        "csr": "99.2",
        "line_coverage": "77.05",
        "branch_coverage": "45.23",
        "dataset": "symprompt",
        "lang": "python",
        "task": "unit_test_generation"
      }
    },
    "GPT-4.1-2025-04-14": {
      "overall": {
        "rank": 11,
        "csr": "99.2",
        "line_coverage": "75.42",
        "branch_coverage": "44.48",
        "dataset": "symprompt",
        "lang": "python",
        "task": "unit_test_generation"
      }
    },
    "GPT-5": {
      "overall": {
        "rank": 12,
        "csr": "99.2",
        "line_coverage": "82.63",
        "branch_coverage": "50.28",
        "dataset": "symprompt",
        "lang": "python",
        "task": "unit_test_generation"
      }
    },
    "Gemini-2.5-Pro-05-06": {
      "overall": {
        "rank": 13,
        "csr": "99.0",
        "line_coverage": "32.56",
        "branch_coverage": "15.45",
        "dataset": "symprompt",
        "lang": "python",
        "task": "unit_test_generation"
      }
    },
    "Qwen2.5-72B-Instruct": {
      "overall": {
        "rank": 14,
        "csr": "99.0",
        "line_coverage": "64.78",
        "branch_coverage": "34.45",
        "dataset": "symprompt",
        "lang": "python",
        "task": "unit_test_generation"
      }
    },
    "Qwen3-32B": {
      "overall": {
        "rank": 15,
        "csr": "99.0",
        "line_coverage": "65.23",
        "branch_coverage": "35.80",
        "dataset": "symprompt",
        "lang": "python",
        "task": "unit_test_generation"
      }
    },
    "DeepSeek-V3": {
      "overall": {
        "rank": 16,
        "csr": "98.8",
        "line_coverage": "68.61",
        "branch_coverage": "39.04",
        "dataset": "symprompt",
        "lang": "python",
        "task": "unit_test_generation"
      }
    },
    "GPT-3.5-turbo-0125": {
      "overall": {
        "rank": 17,
        "csr": "98.8",
        "line_coverage": "67.47",
        "branch_coverage": "34.09",
        "dataset": "symprompt",
        "lang": "python",
        "task": "unit_test_generation"
      }
    },
    "DeepSeek-R1 (0528)": {
      "overall": {
        "rank": 18,
        "csr": "98.7",
        "line_coverage": "67.39",
        "branch_coverage": "36.16",
        "dataset": "symprompt",
        "lang": "python",
        "task": "unit_test_generation"
      }
    },
    "DeepSeek-R1": {
      "overall": {
        "rank": 19,
        "csr": "98.5",
        "line_coverage": "69.01",
        "branch_coverage": "38.65",
        "dataset": "symprompt",
        "lang": "python",
        "task": "unit_test_generation"
      }
    },
    "GPT-4o-2024-11-20": {
      "overall": {
        "rank": 20,
        "csr": "98.5",
        "line_coverage": "69.34",
        "branch_coverage": "39.11",
        "dataset": "symprompt",
        "lang": "python",
        "task": "unit_test_generation"
      }
    },
    "Llama-3.1-70B-Instruct": {
      "overall": {
        "rank": 21,
        "csr": "98.5",
        "line_coverage": "66.29",
        "branch_coverage": "34.55",
        "dataset": "symprompt",
        "lang": "python",
        "task": "unit_test_generation"
      }
    },
    "Grok-3-Mini (High)": {
      "overall": {
        "rank": 22,
        "csr": "98.3",
        "line_coverage": "65.86",
        "branch_coverage": "38.42",
        "dataset": "symprompt",
        "lang": "python",
        "task": "unit_test_generation"
      }
    },
    "Llama-3.3-70B-Instruct": {
      "overall": {
        "rank": 23,
        "csr": "98.3",
        "line_coverage": "66.67",
        "branch_coverage": "35.69",
        "dataset": "symprompt",
        "lang": "python",
        "task": "unit_test_generation"
      }
    },
    "Llama-4-Scout-17B-16E-Instruct": {
      "overall": {
        "rank": 24,
        "csr": "97.7",
        "line_coverage": "68.68",
        "branch_coverage": "35.88",
        "dataset": "symprompt",
        "lang": "python",
        "task": "unit_test_generation"
      }
    },
    "Gemma-3-27b-it": {
      "overall": {
        "rank": 25,
        "csr": "97.5",
        "line_coverage": "64.69",
        "branch_coverage": "34.64",
        "dataset": "symprompt",
        "lang": "python",
        "task": "unit_test_generation"
      }
    },
    "Llama-3.1-8B-Instruct": {
      "overall": {
        "rank": 26,
        "csr": "96.0",
        "line_coverage": "46.01",
        "branch_coverage": "20.75",
        "dataset": "symprompt",
        "lang": "python",
        "task": "unit_test_generation"
      }
    }
  }
}